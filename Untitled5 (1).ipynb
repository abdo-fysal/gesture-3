{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "[[[0.44525547 0.55474453]\n",
      "  [0.42576029 0.57423971]\n",
      "  [0.18275418 0.81724582]\n",
      "  [0.54211663 0.45788337]\n",
      "  [0.43767573 0.56232427]\n",
      "  [0.53301887 0.46698113]\n",
      "  [0.71258503 0.28741497]\n",
      "  [0.53021665 0.46978335]\n",
      "  [0.43949661 0.56050339]\n",
      "  [0.42599278 0.57400722]\n",
      "  [0.53898305 0.46101695]\n",
      "  [0.53100338 0.46899662]\n",
      "  [0.53033708 0.46966292]\n",
      "  [0.52980877 0.47019123]\n",
      "  [0.5276212  0.4723788 ]\n",
      "  [0.57072571 0.42927429]\n",
      "  [0.72929293 0.27070707]\n",
      "  [0.70693069 0.29306931]\n",
      "  [0.69607843 0.30392157]\n",
      "  [0.55844156 0.44155844]\n",
      "  [0.55144695 0.44855305]\n",
      "  [0.54285714 0.45714286]\n",
      "  [0.68623853 0.31376147]]]\n",
      "INFO:tensorflow:Restoring parameters from ./gesture_model2\n",
      "class 3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import webbrowser\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, 23, 2])\n",
    "n_input=2\n",
    "n_hidden=32\n",
    "n_classes=4\n",
    "\n",
    "\n",
    "# Graph weights\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])), # Hidden layer weights\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes], mean=1.0))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "pred = LSTM_RNN(x, weights, biases)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "# Environment:\n",
    "# OS    : Mac OS EL Capitan\n",
    "# python: 3.5\n",
    "# opencv: 2.4.13\n",
    "\n",
    "# parameters\n",
    "cap_region_x_begin=0  # start point/total width\n",
    "cap_region_y_end=1  # start point/total width\n",
    "threshold = 60  #  BINARY threshold\n",
    "blurValue = 41  # GaussianBlur parameter\n",
    "bgSubThreshold = 50\n",
    "\n",
    "# variables\n",
    "isBgCaptured = 0   # bool, whether the background captured\n",
    "triggerSwitch = False  # if true, keyborad simulator works\n",
    "\n",
    "def printThreshold(thr):\n",
    "    print(\"! Changed threshold to \"+str(thr))\n",
    "\n",
    "\n",
    "def removeBG(frame):\n",
    "    fgmask = bgModel.apply(frame)\n",
    "    # kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    # res = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    fgmask = cv2.erode(fgmask, kernel, iterations=1)\n",
    "    res = cv2.bitwise_and(frame, frame, mask=fgmask)\n",
    "    return res\n",
    "\n",
    "\n",
    "def calculateFingers(res,drawing):  # -> finished bool, cnt: finger count\n",
    "    #  convexity defect\n",
    "    hull = cv2.convexHull(res, returnPoints=False)\n",
    "    if len(hull) > 3:\n",
    "        defects = cv2.convexityDefects(res, hull)\n",
    "        if type(defects) != type(None):  # avoid crashing.   (BUG not found)\n",
    "\n",
    "            cnt = 0\n",
    "            for i in range(defects.shape[0]):  # calculate the angle\n",
    "                s, e, f, d = defects[i][0]\n",
    "                start = tuple(res[s][0])\n",
    "                end = tuple(res[e][0])\n",
    "                far = tuple(res[f][0])\n",
    "                a = math.sqrt((end[0] - start[0]) ** 2 + (end[1] - start[1]) ** 2)\n",
    "                b = math.sqrt((far[0] - start[0]) ** 2 + (far[1] - start[1]) ** 2)\n",
    "                c = math.sqrt((end[0] - far[0]) ** 2 + (end[1] - far[1]) ** 2)\n",
    "                angle = math.acos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c))  # cosine theorem\n",
    "                if angle <= math.pi / 2:  # angle less than 90 degree, treat as fingers\n",
    "                    cnt += 1\n",
    "                    cv2.circle(drawing, far, 8, [211, 84, 0], -1)\n",
    "            return True, cnt\n",
    "    return False, 0\n",
    "\n",
    "\n",
    "# Camera\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "camera.set(10,200)\n",
    "cv2.namedWindow('trackbar')\n",
    "cv2.createTrackbar('trh1', 'trackbar', threshold, 100, printThreshold)\n",
    "\n",
    "j=0\n",
    "ret, frame = camera.read()\n",
    "bgModel = cv2.createBackgroundSubtractorMOG2(0, bgSubThreshold)\n",
    "isBgCaptured = 1\n",
    "l=[]\n",
    "o=1\n",
    "while len(l)<23:\n",
    "    print(j)\n",
    "    ret, frame = camera.read()\n",
    "    if o:\n",
    "        \n",
    "        frame = cv2.resize(frame, (480, 640)) \n",
    "    \n",
    "        threshold = cv2.getTrackbarPos('trh1', 'trackbar')\n",
    "        frame = cv2.bilateralFilter(frame, 5, 50, 100)  # smoothing filter\n",
    "        frame = cv2.flip(frame, 1)  # flip the frame horizontally\n",
    "        cv2.rectangle(frame, (int(cap_region_x_begin * frame.shape[1]), 0),\n",
    "                     (frame.shape[1], int(cap_region_y_end * frame.shape[0])), (255, 0, 0), 2)\n",
    "       # cv2.imshow('original', frame)\n",
    "        \n",
    "    #  Main operation\n",
    "        if isBgCaptured == 1:  # this part wont run until background captured\n",
    "            img = removeBG(frame)\n",
    "            img = img[0:int(cap_region_y_end * frame.shape[0]),\n",
    "                        int(cap_region_x_begin * frame.shape[1]):frame.shape[1]]  # clip the ROI\n",
    "           # cv2.imshow('mask', img)\n",
    "\n",
    "        # convert the image into binary image\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            blur = cv2.GaussianBlur(gray, (blurValue, blurValue), 0)\n",
    "            #cv2.imshow('blur', blur)\n",
    "            ret, thresh = cv2.threshold(blur, threshold, 255, cv2.THRESH_BINARY)\n",
    "            #cv2.imshow('ori', thresh)\n",
    "\n",
    "\n",
    "        # get the coutours\n",
    "            thresh1 = copy.deepcopy(thresh)\n",
    "            im,contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            length = len(contours)\n",
    "            maxArea = -1\n",
    "            if length > 0:\n",
    "                for i in range(length):  # find the biggest contour (according to area)\n",
    "                    temp = contours[i]\n",
    "                    area = cv2.contourArea(temp)\n",
    "                    if area > maxArea:\n",
    "                        maxArea = area\n",
    "                        ci = i\n",
    "\n",
    "                res = contours[ci]\n",
    "                hull = cv2.convexHull(res)\n",
    "                M = cv2.moments(res)\n",
    "                cx=0\n",
    "                cy=0\n",
    "            \n",
    "                if M['m00']!=0  :\n",
    "                    cx = int(M['m10']/M['m00'])\n",
    "                    cy = int(M['m01']/M['m00'])\n",
    "                    c=cx+cy\n",
    "                    cx=cx/c\n",
    "                    cy=cy/c\n",
    "                    l.append([cx,cy])\n",
    "                    j=j+1\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                with open('E:\\\\s.pkl', 'wb') as fp:\n",
    "                \n",
    "                    pickle.dump(l, fp)\n",
    "                \n",
    "            \n",
    "                drawing = np.zeros(img.shape, np.uint8)\n",
    "                cv2.drawContours(drawing, [res], 0, (0, 255, 0), 2)\n",
    "                cv2.drawContours(drawing, [hull], 0, (0, 0, 255), 3)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "                isFinishCal,cnt = calculateFingers(res,drawing)\n",
    "                if triggerSwitch is True:\n",
    "                    if isFinishCal is True and cnt <= 2:\n",
    "                        print (cnt)\n",
    "                        app('System Events').keystroke(' ')  # simulate pressing blank space\n",
    "\n",
    "            #cv2.imshow('output', drawing)\n",
    "        \n",
    "    # Keyboard OP\n",
    "    \n",
    "xx=np.array([l])\n",
    "\n",
    "print(xx)\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "  \n",
    "    saver.restore(sess, \"./gesture_model2\")\n",
    "    \n",
    "\n",
    "    p = sess.run(\n",
    "        [pred],\n",
    "        feed_dict={\n",
    "            x: xx\n",
    "           \n",
    "        }\n",
    "    )\n",
    "\n",
    "    \n",
    "    s=np.argmax(p)\n",
    "    if s==0:\n",
    "        \n",
    "        print('class 1')\n",
    "        webbrowser.open('https://www.facebook.com/')\n",
    "        \n",
    "    elif s==1:\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('class 2') #https://github.com/\n",
    "        \n",
    "    elif s==2:\n",
    "        \n",
    "        \n",
    "        print('class 3')\n",
    "        webbrowser.open('https://github.com/')\n",
    "        \n",
    "    elif s==3:\n",
    "        \n",
    "        \n",
    "        print('class 4')\n",
    "        webbrowser.open('http://www.mazika2day.com/')\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920\n",
      "92\n",
      "40\n",
      "4\n",
      "[[0.28473803 0.71526194]\n",
      " [0.28392246 0.71607757]\n",
      " [0.42607003 0.57392997]\n",
      " [0.29893237 0.7010676 ]\n",
      " [0.3067633  0.6932367 ]\n",
      " [0.31565967 0.6843403 ]\n",
      " [0.3164721  0.6835279 ]\n",
      " [0.33425796 0.66574204]\n",
      " [0.34582132 0.6541787 ]\n",
      " [0.36875    0.63125   ]\n",
      " [0.4088586  0.5911414 ]\n",
      " [0.392555   0.607445  ]\n",
      " [0.42344046 0.57655954]\n",
      " [0.417603   0.582397  ]\n",
      " [0.41491395 0.58508605]\n",
      " [0.35493827 0.64506173]\n",
      " [0.34359807 0.65640193]\n",
      " [0.33280757 0.6671924 ]\n",
      " [0.35433072 0.6456693 ]\n",
      " [0.34477612 0.6552239 ]\n",
      " [0.33001423 0.6699858 ]\n",
      " [0.32085562 0.6791444 ]\n",
      " [0.3109137  0.6890863 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "LABELS = [    \n",
    "    \"JUMPING\",\n",
    "    \"JUMPING_JACKS\",\n",
    "    \"BOXING\",\n",
    "    \"WAVING_2HANDS\",\n",
    "    \"WAVING_1HAND\",\n",
    "    \"CLAPPING_HANDS\"\n",
    "\n",
    "] \n",
    "X_train_path = \"x.txt\"\n",
    "X_test_path = \"x_t.txt\"\n",
    "\n",
    "y_train_path = \"y.txt\"\n",
    "y_test_path = \"y_t.txt\"\n",
    "n_steps = 23\n",
    "\n",
    "def load_X(X_path):\n",
    "    file = open(X_path, 'r')\n",
    "    X_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row.split(',') for row in file\n",
    "        ]], \n",
    "        dtype=np.float32\n",
    "    )\n",
    "    file.close()\n",
    "    print(len(X_))\n",
    "    blocks = int(len(X_) / n_steps)\n",
    "    \n",
    "    X_ = np.array(np.split(X_,blocks))\n",
    "\n",
    "    return X_ \n",
    "def load_y(y_path):\n",
    "    file = open(y_path, 'r')\n",
    "    X_ = np.array(\n",
    "        [elem for elem in [\n",
    "            row for row in file\n",
    "        ]], \n",
    "        dtype=np.float32\n",
    "    )\n",
    "    file.close()\n",
    "    print(len(X_))\n",
    "    blocks = int(len(X_) / 1)\n",
    "    \n",
    "    X_ = np.array(np.split(X_,blocks))\n",
    "\n",
    "    return X_ \n",
    "X_train = load_X(X_train_path)\n",
    "X_test = load_X(X_test_path)\n",
    "#print X_test\n",
    "\n",
    "y_train = load_y(y_train_path)\n",
    "\n",
    "y_test = load_y(y_test_path)\n",
    "print(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(X shape, y shape, every X's mean, every X's standard deviation)\n",
      "(40, 23, 2) (4, 1) 0.5 0.18428706\n",
      "\n",
      "The dataset has not been preprocessed, is not normalised etc\n"
     ]
    }
   ],
   "source": [
    "training_data_count = len(X_train)  # 4519 training series (with 50% overlap between each serie)\n",
    "test_data_count = len(X_test)\n",
    "n_input = len(X_train[0][0])  # num input parameters per timestep\n",
    "\n",
    "n_hidden = 32 # Hidden layer num of features\n",
    "n_classes = 4 \n",
    "\n",
    "learning_rate = 0.0025\n",
    "lambda_loss_amount = 0.0015\n",
    "\n",
    "training_iters = training_data_count *600  # Loop 600 times on the dataset\n",
    "batch_size = 20\n",
    "display_iter = 100  # To show test set accuracy during training\n",
    "\n",
    "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
    "print(X_train.shape, y_test.shape, np.mean(X_test), np.std(X_test))\n",
    "print(\"\\nThe dataset has not been preprocessed, is not normalised etc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LSTM_RNN(_X, _weights, _biases):\n",
    "    # model architecture based on \"guillaume-chevalier\" and \"aymericdamien\" under the MIT license.\n",
    "\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
    "    _X = tf.reshape(_X, [-1, n_input])   \n",
    "    # Rectifies Linear Unit activation function used\n",
    "    _X = tf.nn.relu(tf.matmul(_X, _weights['hidden']) + _biases['hidden'])\n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    _X = tf.split(_X, n_steps, 0) \n",
    "\n",
    "    # Define two stacked LSTM cells (two recurrent layers deep) with tensorflow\n",
    "    lstm_cell_1 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cell_2 = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell_1, lstm_cell_2], state_is_tuple=True)\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cells, _X, dtype=tf.float32)\n",
    "\n",
    "    # A single output is produced, in style of \"many to one\" classifier, refer to http://karpathy.github.io/2015/05/21/rnn-effectiveness/ for details\n",
    "    lstm_last_output = outputs[-1]\n",
    "    \n",
    "    # Linear activation\n",
    "    return tf.matmul(lstm_last_output, _weights['out']) + _biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_batch_size(_train, step, batch_size):\n",
    "    # Function to fetch a \"batch_size\" amount of data from \"(X|y)_train\" data. \n",
    "    \n",
    "    shape = list(_train.shape)\n",
    "    shape[0] = batch_size\n",
    "    batch_s = np.empty(shape)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Loop index\n",
    "        index = ((step-1)*batch_size + i) % len(_train)\n",
    "        batch_s[i] = _train[index] \n",
    "\n",
    "    return batch_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(y_):\n",
    "    # One hot encoding of the network outputs\n",
    "    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "    \n",
    "    y_ = y_.reshape(len(y_))\n",
    "    n_values = int(np.max(y_)) + 1\n",
    "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]  # Returns FLOATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Graph input/output\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_steps, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Graph weights\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])), # Hidden layer weights\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes], mean=1.0))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "pred = LSTM_RNN(x, weights, biases)\n",
    "\n",
    "# Loss, optimizer and evaluation\n",
    "l2 = lambda_loss_amount * sum(\n",
    "    tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()\n",
    ") # L2 loss prevents this overkill neural network to overfit the data\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)) + l2 # Softmax loss\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iter #20:   Batch Loss = 2.962811, Accuracy = 0.5\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.5010323524475098, Accuracy = 0.25\n",
      "Training iter #100:   Batch Loss = 1.981693, Accuracy = 0.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.847970724105835, Accuracy = 0.25\n",
      "Training iter #200:   Batch Loss = 1.756186, Accuracy = 0.5\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.8414369821548462, Accuracy = 0.25\n",
      "Training iter #300:   Batch Loss = 1.788799, Accuracy = 0.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.766028642654419, Accuracy = 0.25\n",
      "Training iter #400:   Batch Loss = 1.803482, Accuracy = 0.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.7589001655578613, Accuracy = 0.25\n",
      "Training iter #500:   Batch Loss = 1.706694, Accuracy = 0.20000000298023224\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.760594129562378, Accuracy = 0.5\n",
      "Training iter #600:   Batch Loss = 1.792103, Accuracy = 0.05000000074505806\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.750739336013794, Accuracy = 0.25\n",
      "Training iter #700:   Batch Loss = 1.691496, Accuracy = 0.44999998807907104\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.743432641029358, Accuracy = 0.0\n",
      "Training iter #800:   Batch Loss = 1.741109, Accuracy = 0.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.7418320178985596, Accuracy = 0.25\n",
      "Training iter #900:   Batch Loss = 1.732613, Accuracy = 0.20000000298023224\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.7389875650405884, Accuracy = 0.25\n",
      "Training iter #1000:   Batch Loss = 1.701489, Accuracy = 0.5\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.7366124391555786, Accuracy = 0.5\n",
      "Training iter #1100:   Batch Loss = 1.688537, Accuracy = 0.3499999940395355\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.7339465618133545, Accuracy = 0.25\n",
      "Training iter #1200:   Batch Loss = 1.735683, Accuracy = 0.30000001192092896\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.7321984767913818, Accuracy = 0.25\n",
      "Training iter #1300:   Batch Loss = 1.647978, Accuracy = 0.4000000059604645\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.7307686805725098, Accuracy = 0.5\n",
      "Training iter #1400:   Batch Loss = 1.700526, Accuracy = 0.3499999940395355\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.7300231456756592, Accuracy = 0.25\n",
      "Training iter #1500:   Batch Loss = 1.652953, Accuracy = 0.30000001192092896\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.7292535305023193, Accuracy = 0.5\n",
      "Training iter #1600:   Batch Loss = 1.675072, Accuracy = 0.4000000059604645\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.7310372591018677, Accuracy = 0.25\n",
      "Training iter #1700:   Batch Loss = 1.617029, Accuracy = 0.3499999940395355\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.730926752090454, Accuracy = 0.5\n",
      "Training iter #1800:   Batch Loss = 1.652064, Accuracy = 0.44999998807907104\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.732500433921814, Accuracy = 0.25\n",
      "Training iter #1900:   Batch Loss = 1.588878, Accuracy = 0.3499999940395355\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.7234342098236084, Accuracy = 0.5\n",
      "Training iter #2000:   Batch Loss = 1.633857, Accuracy = 0.4000000059604645\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.7099788188934326, Accuracy = 0.25\n",
      "Training iter #2100:   Batch Loss = 1.526008, Accuracy = 0.5\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.6809004545211792, Accuracy = 0.5\n",
      "Training iter #2200:   Batch Loss = 1.611891, Accuracy = 0.3499999940395355\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.6382660865783691, Accuracy = 0.25\n",
      "Training iter #2300:   Batch Loss = 1.458120, Accuracy = 0.5\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.581055760383606, Accuracy = 0.5\n",
      "Training iter #2400:   Batch Loss = 1.553916, Accuracy = 0.4000000059604645\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.5126092433929443, Accuracy = 0.25\n",
      "Training iter #2500:   Batch Loss = 1.423946, Accuracy = 0.44999998807907104\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.4809505939483643, Accuracy = 0.5\n",
      "Training iter #2600:   Batch Loss = 1.508735, Accuracy = 0.44999998807907104\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.4787710905075073, Accuracy = 0.25\n",
      "Training iter #2700:   Batch Loss = 1.374204, Accuracy = 0.5\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.4579905271530151, Accuracy = 0.0\n",
      "Training iter #2800:   Batch Loss = 1.438969, Accuracy = 0.550000011920929\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.4068377017974854, Accuracy = 0.0\n",
      "Training iter #2900:   Batch Loss = 1.288944, Accuracy = 0.550000011920929\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.3619823455810547, Accuracy = 0.25\n",
      "Training iter #3000:   Batch Loss = 1.386692, Accuracy = 0.5\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.23910653591156, Accuracy = 0.5\n",
      "Training iter #3100:   Batch Loss = 1.150591, Accuracy = 0.6000000238418579\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.1199960708618164, Accuracy = 0.75\n",
      "Training iter #3200:   Batch Loss = 1.321585, Accuracy = 0.550000011920929\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.1338717937469482, Accuracy = 0.5\n",
      "Training iter #3300:   Batch Loss = 1.130963, Accuracy = 0.6499999761581421\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.458612322807312, Accuracy = 0.25\n",
      "Training iter #3400:   Batch Loss = 1.367237, Accuracy = 0.4000000059604645\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.2622013092041016, Accuracy = 0.5\n",
      "Training iter #3500:   Batch Loss = 1.530348, Accuracy = 0.44999998807907104\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.5283304452896118, Accuracy = 0.5\n",
      "Training iter #3600:   Batch Loss = 1.351717, Accuracy = 0.5\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.5506243705749512, Accuracy = 0.25\n",
      "Training iter #3700:   Batch Loss = 1.156434, Accuracy = 0.75\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.2596790790557861, Accuracy = 0.5\n",
      "Training iter #3800:   Batch Loss = 1.399244, Accuracy = 0.3499999940395355\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.2776223421096802, Accuracy = 0.5\n",
      "Training iter #3900:   Batch Loss = 1.158980, Accuracy = 0.6499999761581421\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.2776943445205688, Accuracy = 0.5\n",
      "Training iter #4000:   Batch Loss = 1.127616, Accuracy = 0.699999988079071\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.2970201969146729, Accuracy = 0.5\n",
      "Training iter #4100:   Batch Loss = 0.992987, Accuracy = 0.75\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.1934208869934082, Accuracy = 0.5\n",
      "Training iter #4200:   Batch Loss = 1.101083, Accuracy = 0.6499999761581421\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.2287704944610596, Accuracy = 0.5\n",
      "Training iter #4300:   Batch Loss = 0.940117, Accuracy = 0.699999988079071\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.2111421823501587, Accuracy = 0.75\n",
      "Training iter #4400:   Batch Loss = 1.007955, Accuracy = 0.699999988079071\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.1964807510375977, Accuracy = 0.75\n",
      "Training iter #4500:   Batch Loss = 0.866834, Accuracy = 0.699999988079071\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.0007884502410889, Accuracy = 0.5\n",
      "Training iter #4600:   Batch Loss = 0.874382, Accuracy = 0.800000011920929\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.2097294330596924, Accuracy = 0.5\n",
      "Training iter #4700:   Batch Loss = 0.818206, Accuracy = 0.800000011920929\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.0397820472717285, Accuracy = 0.25\n",
      "Training iter #4800:   Batch Loss = 0.862241, Accuracy = 0.75\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 0.9237680435180664, Accuracy = 0.5\n",
      "Training iter #4900:   Batch Loss = 0.936669, Accuracy = 0.6499999761581421\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 0.9851647615432739, Accuracy = 0.5\n",
      "Training iter #5000:   Batch Loss = 0.802090, Accuracy = 0.8500000238418579\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.6455981731414795, Accuracy = 0.25\n",
      "Training iter #5100:   Batch Loss = 0.778365, Accuracy = 0.75\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.270601749420166, Accuracy = 0.5\n",
      "Training iter #5200:   Batch Loss = 0.704337, Accuracy = 0.8999999761581421\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.6113672256469727, Accuracy = 0.5\n",
      "Training iter #5300:   Batch Loss = 0.610036, Accuracy = 0.949999988079071\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.5402195453643799, Accuracy = 0.5\n",
      "Training iter #5400:   Batch Loss = 0.543374, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.2783610820770264, Accuracy = 0.5\n",
      "Training iter #5500:   Batch Loss = 0.503808, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.5595818758010864, Accuracy = 0.5\n",
      "Training iter #5600:   Batch Loss = 0.727469, Accuracy = 0.75\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.3826396465301514, Accuracy = 0.5\n",
      "Training iter #5700:   Batch Loss = 0.659159, Accuracy = 0.8999999761581421\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.846452236175537, Accuracy = 0.5\n",
      "Training iter #5800:   Batch Loss = 0.522684, Accuracy = 0.949999988079071\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 1.3913843631744385, Accuracy = 0.5\n",
      "Training iter #5900:   Batch Loss = 0.623868, Accuracy = 0.8500000238418579\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.247326374053955, Accuracy = 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iter #6000:   Batch Loss = 0.621786, Accuracy = 0.8500000238418579\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.565157890319824, Accuracy = 0.5\n",
      "Training iter #6100:   Batch Loss = 0.528928, Accuracy = 0.8999999761581421\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.057204484939575, Accuracy = 0.5\n",
      "Training iter #6200:   Batch Loss = 0.511304, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.180210590362549, Accuracy = 0.5\n",
      "Training iter #6300:   Batch Loss = 0.439613, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.18383526802063, Accuracy = 0.5\n",
      "Training iter #6400:   Batch Loss = 0.440584, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.2594385147094727, Accuracy = 0.5\n",
      "Training iter #6500:   Batch Loss = 0.413892, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.5035746097564697, Accuracy = 0.5\n",
      "Training iter #6600:   Batch Loss = 0.402713, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.5591390132904053, Accuracy = 0.5\n",
      "Training iter #6700:   Batch Loss = 0.379569, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.577340602874756, Accuracy = 0.5\n",
      "Training iter #6800:   Batch Loss = 0.372724, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.56349515914917, Accuracy = 0.5\n",
      "Training iter #6900:   Batch Loss = 0.370562, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.3520009517669678, Accuracy = 0.5\n",
      "Training iter #7000:   Batch Loss = 0.362165, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.3898119926452637, Accuracy = 0.5\n",
      "Training iter #7100:   Batch Loss = 0.356657, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.4413866996765137, Accuracy = 0.5\n",
      "Training iter #7200:   Batch Loss = 0.350219, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.497570276260376, Accuracy = 0.5\n",
      "Training iter #7300:   Batch Loss = 0.348674, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.526315689086914, Accuracy = 0.5\n",
      "Training iter #7400:   Batch Loss = 0.344343, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.646268844604492, Accuracy = 0.5\n",
      "Training iter #7500:   Batch Loss = 0.343713, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.7136330604553223, Accuracy = 0.5\n",
      "Training iter #7600:   Batch Loss = 0.339521, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.7670540809631348, Accuracy = 0.5\n",
      "Training iter #7700:   Batch Loss = 0.339070, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.759823799133301, Accuracy = 0.5\n",
      "Training iter #7800:   Batch Loss = 0.335788, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.8245155811309814, Accuracy = 0.5\n",
      "Training iter #7900:   Batch Loss = 0.335815, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.8287229537963867, Accuracy = 0.5\n",
      "Training iter #8000:   Batch Loss = 0.332631, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.8631539344787598, Accuracy = 0.5\n",
      "Training iter #8100:   Batch Loss = 0.332717, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.8582522869110107, Accuracy = 0.5\n",
      "Training iter #8200:   Batch Loss = 0.330026, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.893801689147949, Accuracy = 0.5\n",
      "Training iter #8300:   Batch Loss = 0.329868, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.8918776512145996, Accuracy = 0.5\n",
      "Training iter #8400:   Batch Loss = 0.327594, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.9188072681427, Accuracy = 0.5\n",
      "Training iter #8500:   Batch Loss = 0.327258, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.918450117111206, Accuracy = 0.5\n",
      "Training iter #8600:   Batch Loss = 0.325256, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.945995569229126, Accuracy = 0.5\n",
      "Training iter #8700:   Batch Loss = 0.324834, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.9460554122924805, Accuracy = 0.5\n",
      "Training iter #8800:   Batch Loss = 0.323028, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.97092342376709, Accuracy = 0.5\n",
      "Training iter #8900:   Batch Loss = 0.322524, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.9717047214508057, Accuracy = 0.5\n",
      "Training iter #9000:   Batch Loss = 0.320871, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.995638132095337, Accuracy = 0.5\n",
      "Training iter #9100:   Batch Loss = 0.320317, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 2.995187520980835, Accuracy = 0.5\n",
      "Training iter #9200:   Batch Loss = 0.318784, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.0166738033294678, Accuracy = 0.5\n",
      "Training iter #9300:   Batch Loss = 0.318188, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.0166168212890625, Accuracy = 0.5\n",
      "Training iter #9400:   Batch Loss = 0.316753, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.038125991821289, Accuracy = 0.5\n",
      "Training iter #9500:   Batch Loss = 0.316124, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.038127899169922, Accuracy = 0.5\n",
      "Training iter #9600:   Batch Loss = 0.314772, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.0580220222473145, Accuracy = 0.5\n",
      "Training iter #9700:   Batch Loss = 0.314110, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.0574207305908203, Accuracy = 0.5\n",
      "Training iter #9800:   Batch Loss = 0.312836, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.0764224529266357, Accuracy = 0.5\n",
      "Training iter #9900:   Batch Loss = 0.312146, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.0756771564483643, Accuracy = 0.5\n",
      "Training iter #10000:   Batch Loss = 0.310938, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.0938057899475098, Accuracy = 0.5\n",
      "Training iter #10100:   Batch Loss = 0.310227, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.092683792114258, Accuracy = 0.5\n",
      "Training iter #10200:   Batch Loss = 0.309078, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.110321283340454, Accuracy = 0.5\n",
      "Training iter #10300:   Batch Loss = 0.308346, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.1091582775115967, Accuracy = 0.5\n",
      "Training iter #10400:   Batch Loss = 0.307252, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.126164197921753, Accuracy = 0.5\n",
      "Training iter #10500:   Batch Loss = 0.306499, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.1244497299194336, Accuracy = 0.5\n",
      "Training iter #10600:   Batch Loss = 0.305457, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.1407299041748047, Accuracy = 0.5\n",
      "Training iter #10700:   Batch Loss = 0.304685, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.138590097427368, Accuracy = 0.5\n",
      "Training iter #10800:   Batch Loss = 0.303689, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.1542434692382812, Accuracy = 0.5\n",
      "Training iter #10900:   Batch Loss = 0.302901, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.1516048908233643, Accuracy = 0.5\n",
      "Training iter #11000:   Batch Loss = 0.301946, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.166708469390869, Accuracy = 0.5\n",
      "Training iter #11100:   Batch Loss = 0.301145, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.16361665725708, Accuracy = 0.5\n",
      "Training iter #11200:   Batch Loss = 0.300229, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.178232192993164, Accuracy = 0.5\n",
      "Training iter #11300:   Batch Loss = 0.299414, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.1746878623962402, Accuracy = 0.5\n",
      "Training iter #11400:   Batch Loss = 0.298535, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.1888656616210938, Accuracy = 0.5\n",
      "Training iter #11500:   Batch Loss = 0.297708, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.1849114894866943, Accuracy = 0.5\n",
      "Training iter #11600:   Batch Loss = 0.296863, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.198796272277832, Accuracy = 0.5\n",
      "Training iter #11700:   Batch Loss = 0.296026, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.1945197582244873, Accuracy = 0.5\n",
      "Training iter #11800:   Batch Loss = 0.295212, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.208186149597168, Accuracy = 0.5\n",
      "Training iter #11900:   Batch Loss = 0.294366, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.203660011291504, Accuracy = 0.5\n",
      "Training iter #12000:   Batch Loss = 0.293583, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2171409130096436, Accuracy = 0.5\n",
      "Training iter #12100:   Batch Loss = 0.292728, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.212214469909668, Accuracy = 0.5\n",
      "Training iter #12200:   Batch Loss = 0.291973, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2253618240356445, Accuracy = 0.5\n",
      "Training iter #12300:   Batch Loss = 0.291109, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.219870090484619, Accuracy = 0.5\n",
      "Training iter #12400:   Batch Loss = 0.290383, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2326619625091553, Accuracy = 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iter #12500:   Batch Loss = 0.289509, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2268104553222656, Accuracy = 0.5\n",
      "Training iter #12600:   Batch Loss = 0.288810, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.239502429962158, Accuracy = 0.5\n",
      "Training iter #12700:   Batch Loss = 0.287930, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2333126068115234, Accuracy = 0.5\n",
      "Training iter #12800:   Batch Loss = 0.287254, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.245887041091919, Accuracy = 0.5\n",
      "Training iter #12900:   Batch Loss = 0.286369, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.239401340484619, Accuracy = 0.5\n",
      "Training iter #13000:   Batch Loss = 0.285716, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.251899480819702, Accuracy = 0.5\n",
      "Training iter #13100:   Batch Loss = 0.284826, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.245041608810425, Accuracy = 0.5\n",
      "Training iter #13200:   Batch Loss = 0.284195, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.257380485534668, Accuracy = 0.5\n",
      "Training iter #13300:   Batch Loss = 0.283300, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2501602172851562, Accuracy = 0.5\n",
      "Training iter #13400:   Batch Loss = 0.282689, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.262439250946045, Accuracy = 0.5\n",
      "Training iter #13500:   Batch Loss = 0.281791, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.254974603652954, Accuracy = 0.5\n",
      "Training iter #13600:   Batch Loss = 0.281198, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2672760486602783, Accuracy = 0.5\n",
      "Training iter #13700:   Batch Loss = 0.280298, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.259422779083252, Accuracy = 0.5\n",
      "Training iter #13800:   Batch Loss = 0.279723, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2715864181518555, Accuracy = 0.5\n",
      "Training iter #13900:   Batch Loss = 0.278821, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.263350486755371, Accuracy = 0.5\n",
      "Training iter #14000:   Batch Loss = 0.278263, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2754223346710205, Accuracy = 0.5\n",
      "Training iter #14100:   Batch Loss = 0.277359, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2668299674987793, Accuracy = 0.5\n",
      "Training iter #14200:   Batch Loss = 0.276817, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2789368629455566, Accuracy = 0.5\n",
      "Training iter #14300:   Batch Loss = 0.275911, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.27009654045105, Accuracy = 0.5\n",
      "Training iter #14400:   Batch Loss = 0.275384, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.282245635986328, Accuracy = 0.5\n",
      "Training iter #14500:   Batch Loss = 0.274478, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.273141622543335, Accuracy = 0.5\n",
      "Training iter #14600:   Batch Loss = 0.273965, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.285342216491699, Accuracy = 0.5\n",
      "Training iter #14700:   Batch Loss = 0.273059, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2759807109832764, Accuracy = 0.5\n",
      "Training iter #14800:   Batch Loss = 0.272559, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.288238525390625, Accuracy = 0.5\n",
      "Training iter #14900:   Batch Loss = 0.271654, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2786433696746826, Accuracy = 0.5\n",
      "Training iter #15000:   Batch Loss = 0.271166, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.290987014770508, Accuracy = 0.5\n",
      "Training iter #15100:   Batch Loss = 0.270261, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.281168222427368, Accuracy = 0.5\n",
      "Training iter #15200:   Batch Loss = 0.269785, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.293600559234619, Accuracy = 0.5\n",
      "Training iter #15300:   Batch Loss = 0.268882, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2835745811462402, Accuracy = 0.5\n",
      "Training iter #15400:   Batch Loss = 0.268417, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2961173057556152, Accuracy = 0.5\n",
      "Training iter #15500:   Batch Loss = 0.267515, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2858831882476807, Accuracy = 0.5\n",
      "Training iter #15600:   Batch Loss = 0.267060, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.29852294921875, Accuracy = 0.5\n",
      "Training iter #15700:   Batch Loss = 0.266161, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2880873680114746, Accuracy = 0.5\n",
      "Training iter #15800:   Batch Loss = 0.265714, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3008177280426025, Accuracy = 0.5\n",
      "Training iter #15900:   Batch Loss = 0.264818, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2901759147644043, Accuracy = 0.5\n",
      "Training iter #16000:   Batch Loss = 0.264380, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.302988290786743, Accuracy = 0.5\n",
      "Training iter #16100:   Batch Loss = 0.263486, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.292123317718506, Accuracy = 0.5\n",
      "Training iter #16200:   Batch Loss = 0.263057, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.305018663406372, Accuracy = 0.5\n",
      "Training iter #16300:   Batch Loss = 0.262166, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.293990135192871, Accuracy = 0.5\n",
      "Training iter #16400:   Batch Loss = 0.261744, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3070390224456787, Accuracy = 0.5\n",
      "Training iter #16500:   Batch Loss = 0.260857, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.295884847640991, Accuracy = 0.5\n",
      "Training iter #16600:   Batch Loss = 0.260442, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.30908203125, Accuracy = 0.5\n",
      "Training iter #16700:   Batch Loss = 0.259559, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.297785520553589, Accuracy = 0.5\n",
      "Training iter #16800:   Batch Loss = 0.259150, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3111062049865723, Accuracy = 0.5\n",
      "Training iter #16900:   Batch Loss = 0.258272, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.2996573448181152, Accuracy = 0.5\n",
      "Training iter #17000:   Batch Loss = 0.257869, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3130998611450195, Accuracy = 0.5\n",
      "Training iter #17100:   Batch Loss = 0.256995, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3014943599700928, Accuracy = 0.5\n",
      "Training iter #17200:   Batch Loss = 0.256597, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3150460720062256, Accuracy = 0.5\n",
      "Training iter #17300:   Batch Loss = 0.255727, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.303298234939575, Accuracy = 0.5\n",
      "Training iter #17400:   Batch Loss = 0.255335, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3169608116149902, Accuracy = 0.5\n",
      "Training iter #17500:   Batch Loss = 0.254470, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3050711154937744, Accuracy = 0.5\n",
      "Training iter #17600:   Batch Loss = 0.254082, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3188533782958984, Accuracy = 0.5\n",
      "Training iter #17700:   Batch Loss = 0.253222, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.306828737258911, Accuracy = 0.5\n",
      "Training iter #17800:   Batch Loss = 0.252838, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3207247257232666, Accuracy = 0.5\n",
      "Training iter #17900:   Batch Loss = 0.251984, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3085665702819824, Accuracy = 0.5\n",
      "Training iter #18000:   Batch Loss = 0.251604, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.322585344314575, Accuracy = 0.5\n",
      "Training iter #18100:   Batch Loss = 0.250755, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3103160858154297, Accuracy = 0.5\n",
      "Training iter #18200:   Batch Loss = 0.250378, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3244521617889404, Accuracy = 0.5\n",
      "Training iter #18300:   Batch Loss = 0.249535, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.312094211578369, Accuracy = 0.5\n",
      "Training iter #18400:   Batch Loss = 0.249162, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.326399803161621, Accuracy = 0.5\n",
      "Training iter #18500:   Batch Loss = 0.248323, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.313971996307373, Accuracy = 0.5\n",
      "Training iter #18600:   Batch Loss = 0.247953, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3284544944763184, Accuracy = 0.5\n",
      "Training iter #18700:   Batch Loss = 0.247121, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3160271644592285, Accuracy = 0.5\n",
      "Training iter #18800:   Batch Loss = 0.246753, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.330812931060791, Accuracy = 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iter #18900:   Batch Loss = 0.245927, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.318394422531128, Accuracy = 0.5\n",
      "Training iter #19000:   Batch Loss = 0.245561, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3332934379577637, Accuracy = 0.5\n",
      "Training iter #19100:   Batch Loss = 0.244742, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.320753335952759, Accuracy = 0.5\n",
      "Training iter #19200:   Batch Loss = 0.244377, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3357505798339844, Accuracy = 0.5\n",
      "Training iter #19300:   Batch Loss = 0.243564, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.323101043701172, Accuracy = 0.5\n",
      "Training iter #19400:   Batch Loss = 0.243202, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.338184356689453, Accuracy = 0.5\n",
      "Training iter #19500:   Batch Loss = 0.242395, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.325392484664917, Accuracy = 0.5\n",
      "Training iter #19600:   Batch Loss = 0.242034, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.340573787689209, Accuracy = 0.5\n",
      "Training iter #19700:   Batch Loss = 0.241234, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3276662826538086, Accuracy = 0.5\n",
      "Training iter #19800:   Batch Loss = 0.240874, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3429362773895264, Accuracy = 0.5\n",
      "Training iter #19900:   Batch Loss = 0.240081, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3299248218536377, Accuracy = 0.5\n",
      "Training iter #20000:   Batch Loss = 0.239722, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3452558517456055, Accuracy = 0.5\n",
      "Training iter #20100:   Batch Loss = 0.238935, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.332113742828369, Accuracy = 0.5\n",
      "Training iter #20200:   Batch Loss = 0.238577, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.347565174102783, Accuracy = 0.5\n",
      "Training iter #20300:   Batch Loss = 0.237796, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.334331750869751, Accuracy = 0.5\n",
      "Training iter #20400:   Batch Loss = 0.237440, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.349926710128784, Accuracy = 0.5\n",
      "Training iter #20500:   Batch Loss = 0.236664, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.336698055267334, Accuracy = 0.5\n",
      "Training iter #20600:   Batch Loss = 0.236309, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3524560928344727, Accuracy = 0.5\n",
      "Training iter #20700:   Batch Loss = 0.235540, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3392481803894043, Accuracy = 0.5\n",
      "Training iter #20800:   Batch Loss = 0.235185, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.355225086212158, Accuracy = 0.5\n",
      "Training iter #20900:   Batch Loss = 0.234424, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3420217037200928, Accuracy = 0.5\n",
      "Training iter #21000:   Batch Loss = 0.234069, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.358147621154785, Accuracy = 0.5\n",
      "Training iter #21100:   Batch Loss = 0.233314, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.344917058944702, Accuracy = 0.5\n",
      "Training iter #21200:   Batch Loss = 0.232959, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3611581325531006, Accuracy = 0.5\n",
      "Training iter #21300:   Batch Loss = 0.232212, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3478591442108154, Accuracy = 0.5\n",
      "Training iter #21400:   Batch Loss = 0.231856, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3642306327819824, Accuracy = 0.5\n",
      "Training iter #21500:   Batch Loss = 0.231115, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3508429527282715, Accuracy = 0.5\n",
      "Training iter #21600:   Batch Loss = 0.230761, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.367321252822876, Accuracy = 0.5\n",
      "Training iter #21700:   Batch Loss = 0.230025, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3538599014282227, Accuracy = 0.5\n",
      "Training iter #21800:   Batch Loss = 0.229671, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3704357147216797, Accuracy = 0.5\n",
      "Training iter #21900:   Batch Loss = 0.228942, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.356982707977295, Accuracy = 0.5\n",
      "Training iter #22000:   Batch Loss = 0.228588, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3736934661865234, Accuracy = 0.5\n",
      "Training iter #22100:   Batch Loss = 0.227866, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.36012864112854, Accuracy = 0.5\n",
      "Training iter #22200:   Batch Loss = 0.227511, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3769431114196777, Accuracy = 0.5\n",
      "Training iter #22300:   Batch Loss = 0.226797, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.36330509185791, Accuracy = 0.5\n",
      "Training iter #22400:   Batch Loss = 0.226441, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3802103996276855, Accuracy = 0.5\n",
      "Training iter #22500:   Batch Loss = 0.225734, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3665270805358887, Accuracy = 0.5\n",
      "Training iter #22600:   Batch Loss = 0.225377, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3835506439208984, Accuracy = 0.5\n",
      "Training iter #22700:   Batch Loss = 0.224677, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3697376251220703, Accuracy = 0.5\n",
      "Training iter #22800:   Batch Loss = 0.224319, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3867897987365723, Accuracy = 0.5\n",
      "Training iter #22900:   Batch Loss = 0.223626, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3728628158569336, Accuracy = 0.5\n",
      "Training iter #23000:   Batch Loss = 0.223268, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3899853229522705, Accuracy = 0.5\n",
      "Training iter #23100:   Batch Loss = 0.222581, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.375960350036621, Accuracy = 0.5\n",
      "Training iter #23200:   Batch Loss = 0.222222, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.393191337585449, Accuracy = 0.5\n",
      "Training iter #23300:   Batch Loss = 0.221543, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.379084825515747, Accuracy = 0.5\n",
      "Training iter #23400:   Batch Loss = 0.221182, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3964457511901855, Accuracy = 0.5\n",
      "Training iter #23500:   Batch Loss = 0.220509, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.3822574615478516, Accuracy = 0.5\n",
      "Training iter #23600:   Batch Loss = 0.220148, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.399742603302002, Accuracy = 0.5\n",
      "Training iter #23700:   Batch Loss = 0.219482, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.385498046875, Accuracy = 0.5\n",
      "Training iter #23800:   Batch Loss = 0.219120, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.4031243324279785, Accuracy = 0.5\n",
      "Training iter #23900:   Batch Loss = 0.218460, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.388820171356201, Accuracy = 0.5\n",
      "Training iter #24000:   Batch Loss = 0.218097, Accuracy = 1.0\n",
      "PERFORMANCE ON TEST SET: Batch Loss = 3.406595468521118, Accuracy = 0.5\n",
      "Optimization Finished!\n",
      "FINAL RESULT: Batch Loss = 3.406595468521118, Accuracy = 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./gesture_model2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_losses = []\n",
    "test_accuracies = []\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Perform Training steps with \"batch_size\" amount of example data at each loop\n",
    "step = 1\n",
    "while step * batch_size <= training_iters:\n",
    "    batch_xs = extract_batch_size(X_train, step, batch_size)\n",
    "    batch_ys = one_hot(extract_batch_size(y_train, step, batch_size))\n",
    "    # check that encoded output is same length as num_classes, if not, pad it \n",
    "    if len(batch_ys[0]) < n_classes:\n",
    "        temp_ys = np.zeros((batch_size, n_classes))\n",
    "        temp_ys[:batch_ys.shape[0],:batch_ys.shape[1]] = batch_ys\n",
    "        batch_ys = temp_ys\n",
    "       \n",
    "    \n",
    "\n",
    "    # Fit training using batch data\n",
    "    _, loss, acc = sess.run(\n",
    "        [optimizer, cost, accuracy],\n",
    "        feed_dict={\n",
    "            x: batch_xs, \n",
    "            y: batch_ys\n",
    "        }\n",
    "    )\n",
    "    train_losses.append(loss)\n",
    "    train_accuracies.append(acc)\n",
    "    \n",
    "    # Evaluate network only at some steps for faster training: \n",
    "    if (step*batch_size % display_iter == 0) or (step == 1) or (step * batch_size > training_iters):\n",
    "        \n",
    "        # To not spam console, show training accuracy/loss in this \"if\"\n",
    "        print(\"Training iter #\" + str(step*batch_size) + \\\n",
    "              \":   Batch Loss = \" + \"{:.6f}\".format(loss) + \\\n",
    "              \", Accuracy = {}\".format(acc))\n",
    "        \n",
    "        # Evaluation on the test set (no learning made here - just evaluation for diagnosis)\n",
    "        loss, acc = sess.run(\n",
    "            [cost, accuracy], \n",
    "            feed_dict={\n",
    "                x: X_test,\n",
    "                y: one_hot(y_test)\n",
    "            }\n",
    "        )\n",
    "        test_losses.append(loss)\n",
    "        test_accuracies.append(acc)\n",
    "        print(\"PERFORMANCE ON TEST SET: \" + \\\n",
    "              \"Batch Loss = {}\".format(loss) + \\\n",
    "              \", Accuracy = {}\".format(acc))\n",
    "\n",
    "    step += 1\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# Accuracy for test data\n",
    "\n",
    "one_hot_predictions, accuracy, final_loss = sess.run(\n",
    "    [pred, accuracy, cost],\n",
    "    feed_dict={\n",
    "        x: X_test,\n",
    "        y: one_hot(y_test)\n",
    "    }\n",
    ")\n",
    "\n",
    "test_losses.append(final_loss)\n",
    "test_accuracies.append(accuracy)\n",
    "\n",
    "print(\"FINAL RESULT: \" + \\\n",
    "      \"Batch Loss = {}\".format(final_loss) + \\\n",
    "      \", Accuracy = {}\".format(accuracy))\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"./gesture_model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=[[1,2],[3,4]]\n",
    "x=np.array([x])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def show_webcam(mirror=False):\n",
    "    \n",
    "    \n",
    "    cam = cv2.VideoCapture(0)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        ret_val, img = cam.read()\n",
    "        if mirror: \n",
    "            img = cv2.flip(img, 1)\n",
    "        cv2.imshow('my webcam', img)\n",
    "        if cv2.waitKey(1) == 27: \n",
    "            break  # esc to quit\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def main():\n",
    "    show_webcam(mirror=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
